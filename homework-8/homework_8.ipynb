{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa52b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b727a",
   "metadata": {},
   "source": [
    "Model  \n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.  \n",
    "\n",
    "You need to develop the model with following structure:  \n",
    "\n",
    "    The shape for input should be (3, 200, 200) (channels first format in PyTorch)  \n",
    "    Next, create a convolutional layer (nn.Conv2d):  \n",
    "        Use 32 filters (output channels)  \n",
    "        Kernel size should be (3, 3) (that's the size of the filter), padding = 0, stride = 1  \n",
    "        Use 'relu' as activation  \n",
    "    Reduce the size of the feature map with max pooling (nn.MaxPool2d)  \n",
    "        Set the pooling size to (2, 2)  \n",
    "    Turn the multi-dimensional result into vectors using flatten or view  \n",
    "    Next, add a nn.Linear layer with 64 neurons and 'relu' activation  \n",
    "    Finally, create the nn.Linear layer with 1 neuron - this will be the output  \n",
    "        The output layer should have an activation - use the appropriate activation for the binary classification case  \n",
    "  \n",
    "As optimizer use torch.optim.SGD with the following parameters:  \n",
    "  \n",
    "    torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d83979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b88cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HairDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "\n",
    "        for label_name in self.classes:\n",
    "            label_dir = os.path.join(data_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dc8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple preprocessing\n",
    "\n",
    "input_size = 200\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606bac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "train_dataset = HairDataset(\n",
    "    data_dir='data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "validation_dataset = HairDataset(\n",
    "    data_dir='data/test',\n",
    "    transform=validation_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6880544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HairClassifierCNN200(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HairClassifierCNN200, self).__init__()\n",
    "\n",
    "        # Convolutional layer\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv + ReLU + Pooling\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Linea1 1 + RelU\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        # # Linear 2\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea320a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HairClassifierCNN200()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbdb5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 198, 198]             896\n",
      "              ReLU-2         [-1, 32, 198, 198]               0\n",
      "         MaxPool2d-3           [-1, 32, 99, 99]               0\n",
      "            Linear-4                   [-1, 64]      20,072,512\n",
      "              ReLU-5                   [-1, 64]               0\n",
      "            Linear-6                    [-1, 1]              65\n",
      "================================================================\n",
      "Total params: 20,073,473\n",
      "Trainable params: 20,073,473\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 21.54\n",
      "Params size (MB): 76.57\n",
      "Estimated Total Size (MB): 98.57\n",
      "----------------------------------------------------------------\n",
      "Total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Using torchsummary (install with: pip install torchsummary)\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 200, 200))\n",
    "\n",
    "# Option 2: Manual counting\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246908b4",
   "metadata": {},
   "source": [
    "Question 3 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcb4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple preprocessing\n",
    "\n",
    "input_size = 200\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fadaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "train_dataset = HairDataset(\n",
    "    data_dir='data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "validation_dataset = HairDataset(\n",
    "    data_dir='data/test',\n",
    "    transform=validation_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "150c12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6269, Acc: 0.6454, Val Loss: 0.6720, Val Acc: 0.6020\n",
      "Epoch 2/10, Loss: 0.5853, Acc: 0.6991, Val Loss: 0.6943, Val Acc: 0.6517\n",
      "Epoch 3/10, Loss: 0.5180, Acc: 0.7378, Val Loss: 0.7620, Val Acc: 0.6418\n",
      "Epoch 4/10, Loss: 0.5536, Acc: 0.7141, Val Loss: 0.7362, Val Acc: 0.6070\n",
      "Epoch 5/10, Loss: 0.5057, Acc: 0.7291, Val Loss: 0.6399, Val Acc: 0.6816\n",
      "Epoch 6/10, Loss: 0.4244, Acc: 0.7978, Val Loss: 0.7115, Val Acc: 0.6567\n",
      "Epoch 7/10, Loss: 0.3493, Acc: 0.8352, Val Loss: 0.7469, Val Acc: 0.6169\n",
      "Epoch 8/10, Loss: 0.3363, Acc: 0.8539, Val Loss: 0.6735, Val Acc: 0.6716\n",
      "Epoch 9/10, Loss: 0.2267, Acc: 0.9126, Val Loss: 0.7691, Val Acc: 0.6517\n",
      "Epoch 10/10, Loss: 0.2189, Acc: 0.9139, Val Loss: 0.9655, Val Acc: 0.6915\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc5406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Median of training accuracy: 0.7838951310861424'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Median of training accuracy: {np.mean(history['acc'])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98aeac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Standard deviation of training loss: 0.13878674907896324'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Standard deviation of training loss: {np.std(history['loss'])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23645e0",
   "metadata": {},
   "source": [
    "Question 5  Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76eaed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple preprocessing\n",
    "\n",
    "input_size = 200\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bcf35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "\n",
    "train_dataset = HairDataset(\n",
    "    data_dir='data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "validation_dataset = HairDataset(\n",
    "    data_dir='data/test',\n",
    "    transform=validation_transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a087accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7237, Acc: 0.6392, Val Loss: 0.6721, Val Acc: 0.6468\n",
      "Epoch 2/10, Loss: 0.6211, Acc: 0.6592, Val Loss: 0.9167, Val Acc: 0.5522\n",
      "Epoch 3/10, Loss: 0.6334, Acc: 0.6554, Val Loss: 0.6797, Val Acc: 0.6318\n",
      "Epoch 4/10, Loss: 0.5897, Acc: 0.7016, Val Loss: 0.6452, Val Acc: 0.6468\n",
      "Epoch 5/10, Loss: 0.5706, Acc: 0.7179, Val Loss: 0.5790, Val Acc: 0.7015\n",
      "Epoch 6/10, Loss: 0.5794, Acc: 0.7016, Val Loss: 0.5579, Val Acc: 0.7114\n",
      "Epoch 7/10, Loss: 0.5236, Acc: 0.7441, Val Loss: 0.5471, Val Acc: 0.7015\n",
      "Epoch 8/10, Loss: 0.5479, Acc: 0.7091, Val Loss: 0.5909, Val Acc: 0.6766\n",
      "Epoch 9/10, Loss: 0.5229, Acc: 0.7316, Val Loss: 0.8330, Val Acc: 0.5721\n",
      "Epoch 10/10, Loss: 0.5379, Acc: 0.7141, Val Loss: 0.6173, Val Acc: 0.6766\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c91ec75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean of test loss for all the epochs: 0.6638691819124666'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'mean of test loss for all the epochs: {np.mean(history['val_loss'])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0ac8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average of test accuracy for the last 5 epochs (from 6 to 10): 0.6676616915422885'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Average of test accuracy for the last 5 epochs (from 6 to 10): {np.mean(history['val_acc'][5:])}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b912c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-zoomcamp-ml_models-homeworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
